For the sake of this workshop, everything will be deployed in a single "shared-services" account. However, in production environments you should segment your workloads. The shared services account is typically where your pipelines are stored, as well as potentially your security and AWS organizations/SSO deployments (you could also have a security-specific account). Then the pipeline in in shared-services account should deploy your actual production workloads to production accounts leveraging the CodeBuild portion of CodePipeline. It will either pull from CodeCommit repos within the same (shared-services) account, CodeCommit repos in different AWS accounts (cross-account access), or 3rd party git providers such as GitHub, or GitLab.

1. Run TF code in pipeline directory to create the following AWS resources:
  - [CodePipeline "tf-module-validation"] - Terraform Module Validation Pipeline
    - Uses Terraform test and Checkov to validate module functionality and ensure they are secure. Does NOT use CodeDeploy since no resources are being deployed. Source of this pipeline is CodeCommit Repo
  - [CodePipeline `tf-resource-deployment`] - Terraform Resource Deployment Pipeline
    - Uses created modules to deploy resources to AWS (Amplify App, IAM Roles, S3 buckets, whatever). Uses For the sake
      of this workshop it will all be in a single account but normally you would want to separate it
  - [CodeCommit "devops-core"] - Repo for both pipelines and codecommit repos (core infra for this account), not used by pipeline



Now that the module has been validated with the "tf-module-validation-pipeline", let's use that module to create a sample workload, and use the "tf-deployment-pipeline" to actually deploy the infrastructure.

In terms of patterns, you have two at your disposal and depending on which version of codepipeline you use it can make a difference.

Option 1 - Separate AWS CodePipeline for each of your modules and workload deployments
- This option seems pretty logical - one pipeline mapped to one specific module/workload. The issue comes down to pricing.

V1 Pipeline Type:
If you are using v1 this would be $1.00/mo per active pipeline. Imagine if you have 50 Terraform modules and 20 production deployments. This would be $70 for your pipeline needs, even if some are minimally active.

V2: Pipeline Type:
The pricing becomes substantially more effective in v2. For the same 50 pipelines, you simply pay $0.002 per action minute (excluding manual approval anc custom action types). Even if each of the 70 pipelines took 2 hours to finish running (120 minutes), the cost would be approx. $16.80, a lot less than $70. The savings become even greater if most of your pipelines are short running (likely the case for most of your Terraform module validation pipelines).




Option 2 - Single AWS CodePipeline with multiple sources (multiple repos, etc.)
- In this option you can have a single pipeline for validation of all of your Terraform modules. In the pipeline config you would just add multiple 'source' stages that correspond to each repository. For pricing, currently you pay $0.002 per action execution minute (besides manual approval and custom action types). This can be a bit more straight forward compared to V1 pricing which is $1.00 per active pipeline. Image if you have

HASHICORP DOCKER CONTAINER ON DOCKER HUB: https://hub.docker.com/r/hashicorp/terraform/

environment_image = "hashicorp/terraform:1.7.0" or "hashicorp/terraform" to pull whatever the latest version is on docker hub
